{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import pickle\n",
    "import nltk\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_time_window(start, end, step, length):\n",
    "    \n",
    "    start_datetime_object = datetime.datetime.strptime(start, '%Y-%m-%d')\n",
    "    \n",
    "    end_datetime_object = datetime.datetime.strptime(end, '%Y-%m-%d')\n",
    "\n",
    "    iterator = start_datetime_object\n",
    "    output = []\n",
    "    while iterator < end_datetime_object:\n",
    "        since = str(iterator)[:10]\n",
    "#         until = str(iterator + datetime.timedelta(days=step))[:10]\n",
    "        until = str(min(end_datetime_object, iterator + datetime.timedelta(days=length)))[:10]\n",
    "        output.append((since,until))\n",
    "        iterator += datetime.timedelta(days=step)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_time_window('2018-01-01', '2020-06-04', 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(search, since, until, limit=100, db=True):\n",
    "    dbname = search.replace(\" \",\"_\") + \".db\"\n",
    "    c = twint.Config()\n",
    "    c.Search = search\n",
    "    c.Limit = limit # If not specified, scrapes all...\n",
    "    c.Pandas = True\n",
    "    c.Pandas_clean = True\n",
    "    c.Since = since\n",
    "    c.Until = until\n",
    "    c.Database = dbname\n",
    "    c.Hide_output = True\n",
    "    \n",
    "    twint.run.Search(c)\n",
    "    if db==False:\n",
    "        return twint.output.panda.Tweets_df\n",
    "    else: print(\"Done: \"+ since + \" to \" + until, twint.output.panda.Tweets_df.shape[0], \"entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_to_db(keyword, start_date, end_date, step, length, limit):\n",
    "    dates = gen_time_window(start_date, end_date, step, length)\n",
    "    for i in dates:\n",
    "        get_tweets(keyword, i[0], i[1], limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_to_db(keyword = \"spacex rocket\", \n",
    "             start_date = '2020-01-01', \n",
    "             end_date = '2020-06-01', \n",
    "             step = 30, \n",
    "             length = 1, \n",
    "             limit = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_to_db(keyword = \"digital health\", \n",
    "             start_date = '2018-01-01', \n",
    "             end_date = '2020-06-01', \n",
    "             step = 14, \n",
    "             length = 1, \n",
    "             limit = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = get_tweets(\"digital health\", '2020-06-03','2020-06-04', limit=100)\n",
    "tweets = get_tweets(\"digital health\", '2020-06-01','2020-06-02', limit=100)\n",
    "\n",
    "# tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"max_columns\", None)\n",
    "\n",
    "# pd.reset_option(\"max_rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('gender/top_words.json') as json_file:\n",
    "    top_words = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(top_words, text):\n",
    "    feature = {}\n",
    "    for word in top_words:\n",
    "        feature[word] = word in text.lower()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_classifier = pickle.load(open('gender/gender_NB_classifier.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_classifier.classify(find_features(top_words, tweets['tweet'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['gender'] = tweets['tweet'].apply(lambda x: NB_classifier.classify(find_features(top_words, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gender_classif.ipynb to script\n",
      "[NbConvertApp] Writing 3194 bytes to gender_classif.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script gender_classif.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
